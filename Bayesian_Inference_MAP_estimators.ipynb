{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference: Maximum A Posteriori Probability (MAP) Estimators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X_1, X_2, \\ldots, X_n$ be independent indentically distributed (iid) random variables so that each $X_i$  has a normal distribution $\\mathcal{N}(\\mu, \\sigma^2)$. Let us denote the pdf of this normal distribution by $f(x | \\mu, \\sigma^2)$.\n",
    "\n",
    "Suppose that we have a sample $\\underline{x} = (x_1, \\ldots, x_n)$ where each $x_i$ has been taken from a random variable $X_i$.\n",
    "\n",
    "We would like to estimate the parameters $\\theta = (\\theta_1, \\theta_2) =  (\\mu, \\sigma^2)$ by using Bayesian inference.\n",
    "\n",
    "__Caution__: be extra careful with the parameters: \n",
    "- if you take the parameters to be $(\\mu, \\sigma^2)$ you will need to differentiate with respect to $\\theta_1 = \\mu$ and $\\theta_2 = \\sigma^2$ not $\\theta_2 = \\sigma$ (this may be a bit odd when you differentiate), \n",
    "- if you take the parameters to be $(\\mu, \\sigma)$ then it may be less confusing when taking derivatives."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the Fisher information matrix \n",
    "$$I(\\theta) = - \\left[\\begin{array}{cc} \\mathbb{E}_{\\mu, \\sigma^2}\\left[\\frac{\\partial^2}{ \\partial \\mu^2} \\ell ( \\mu, \\sigma^2)\\right] & \\mathbb{E}_{\\mu, \\sigma^2}\\left[\\frac{\\partial^2}{ \\partial \\mu \\partial \\sigma^2} \\ell ( \\mu, \\sigma^2)\\right]  \\\\ \\mathbb{E}_{\\mu, \\sigma^2}\\left[ \\frac{\\partial^2}{ \\partial \\mu \\partial \\sigma^2} \\ell ( \\mu, \\sigma^2)\\right] & \\mathbb{E}_{\\mu, \\sigma^2}\\left[\\frac{\\partial^2}{ \\partial \\left(\\sigma^2\\right)^2} \\ell ( \\mu, \\sigma^2)\\right] \\end{array} \\right],$$\n",
    "where $\\ell ( \\mu, \\sigma^2) = \\ln (f(X| \\mu, \\sigma^2))$, $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$. \n",
    "- Then take the prior distribution (distribution of the parameters), that is, $\\pi(\\theta)$ to be proportional to $\\sqrt{\\det I(\\theta)}$.\n",
    "- Assuming that $\\theta_1$, $\\theta_2$ are independent, $\\theta_1 \\sim \\mathcal{U}(0, 1)$ and $\\theta_2$ runs from $[a, \\infty)$ for some $a>0$,\n",
    "show that $\\pi(\\theta) = \\pi_1(\\theta_1)\\pi_2(\\theta_2)$, \n",
    "where:\n",
    "\n",
    "\\begin{align*} \n",
    "\\pi_1(\\theta_1) =& 1 \\ \\ \\mathrm{ for }\\ \\theta_1 \\in [0, 1] \\\\ \\pi_2(\\theta_2) =& \\frac{\\sqrt{a}}{2} \\theta_2^{-3/2} \\ \\ \\mathrm{ for } \\ \\theta_2 > a.\n",
    "\\end{align*}\n",
    "- Show that the CDF from $\\pi_2$  is\n",
    "$$ F(x) = \\begin{cases} 1 - \\sqrt{\\frac{a}{x}} & \\mathrm{ for  }\\ x \\geq a \\\\ 0 & \\mathrm{ for } \\ x < a \\end{cases}$$\n",
    "also show that if we restrict the domain of $F$ to be $(a, \\infty)$ then \n",
    "$$F^{-1}(x) = \\frac{a}{(1-x)^2}.$$\n",
    "- Find the likelihood function and conclude the expession that is proportional to the posterior distribution $\\pi(\\theta| \\underline{x})$.\n",
    "- Find the MAP estimator $\\widehat{\\theta}_{\\text{MAP}}$ for $\\theta$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate a sample of size $1000$ from the prior distribution $$\\pi_2( x) = \\frac{\\sqrt{a}}{2}x^{-3/2}, x > a$$ with $a=1$.\n",
    "For that use the CDF inverse from 2a), filter the sample to remove any values larger than $10$ (use slicing, boolean indexing). \n",
    "- Plot its histogram against the density in the range $(a, 10]$.\n",
    "- Generate one value for $\\mu$ from $\\pi_1$ and one value for $\\sigma^2$ from $\\pi_2$. Print $\\mu$ and $\\sigma$.\n",
    "- Generate a sample of size $1000$ from normal distribution with parameters $\\mu$ and $\\sigma^2$. Plot its histogram. \n",
    "- Define the MAP estimators and compare their values with the $\\mu$ and $\\sigma^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi2_cdf_inv(x): #defines the CDF inverse for pi2 from 2a\n",
    "    if x == (1):\n",
    "        print(\"Please choose another value for x\") #stops math error occuring from division by 0\n",
    "        return None\n",
    "    val = 1/((1-x)**2)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_samp_gen(n): #generates a sample of size n from pi2 using the cdf inverse technique\n",
    "    prior_samp = [] #create an empty list to append samples to\n",
    "    while not(len(prior_samp)==n): #using a while not loop to make sure list ends up correct length\n",
    "        x = np.random.uniform() #generates a number [0,1) from uniform dist \n",
    "        y = pi2_cdf_inv(x) #inputs the number into the inverse cdf of pi2\n",
    "        if y<10: #filters any values greater than 10\n",
    "            prior_samp.append(y) #appends values less than 10 into the sample list\n",
    "    return (prior_samp) #returns list of length n with all elements being less than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = prior_samp_gen(1000) #generate a sample of size 1000 from pi2\n",
    "plt.hist(x1, density = True) #creates a histogram with probablilty density plotted on the y-axis\n",
    "# Plot formatting\n",
    "plt.title('Density vs Histogram of prior sample')\n",
    "plt.xticks(np.arange(0,11,1))\n",
    "plt.yticks(np.arange(0,0.55,0.05))\n",
    "plt.xlabel('Sample value')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_sq = np.random.choice(x1) #pi2 generates values for sigma squared, so I just chose a value from the sample generated\n",
    "sig = np.sqrt(sig_sq) #takes the square root to give sigma\n",
    "mu = np.random.uniform() #I found that the cdf of pi1 = mu, which implies the inverse is also mu, so we just take a random number from the uniform distribution \n",
    "print(mu, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate 1000 samples from the normal distribution with parameters mu and sigma\n",
    "normal_sample = np.random.normal(size = 1000,loc = mu, scale = sig)\n",
    "plt.hist(normal_sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define our MAP estimates calculated in 2a\n",
    "def map_mu(data):\n",
    "    return sum(data)/len(data)\n",
    "\n",
    "def map_sig_sq(data, mu):\n",
    "    sum_x1 = 0\n",
    "    N = len(data)\n",
    "    for xi in range(N):\n",
    "        sum_x1+= ((data[xi]-map_mu(data))**2)\n",
    "    return sum_x1/(3+N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we compare our MAP estimates to our mu and sigma squared used as parameters for the data generated above\n",
    "map_mu_est = map_mu(normal_sample)\n",
    "map_sig_sq = map_sig_sq(normal_sample,map_mu_est)\n",
    "\n",
    "print('MAP estimates are:', map_mu_est,map_sig_sq)\n",
    "print('Actual values are:', mu,sig_sq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
